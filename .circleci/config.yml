version: 2.1

commands:
  destroy-environment:
    description: Destroy backend and frontend cloudformation stacks given a workflow ID.
    parameters:
      workflow_id:
        type: string
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            echo "Destroying environment: << parameters.workflow_id >> "
            aws cloudformation delete-stack --stack-name udapeople-backend-<< parameters.workflow_id >>
            aws s3 rm s3://udapeople-<<parameters.workflow_id>> --recursive
            aws cloudformation delete-stack --stack-name udapeople-frontend-<< parameters.workflow_id >>

  revert-migrations:
    description: Revert the last migration
    parameters:
      workflow_id:
        type: string
    steps:
      - run:
          name: Revert migrations
          when: on_fail
          command: |
            SUCCESS=$(curl --insecure  https://kvdb.io/CAaGusCeKyezrNWgEh6TWn/migration_<< parameters.workflow_id >>)
            # Logic for reverting the database state
            if (( $SUCCESS == 1 ));
            then
                cd ~/project/backend
                npm install
                npm run migrations:revert
            fi

jobs:

  build-app:
    docker:
      - image: cimg/ruby:2.7.6
    steps:
      - checkout
      - restore_cache:
          keys:
            - gem-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "Gemfile.lock" }}
            - gem-cache-v1-{{ arch }}-{{ .Branch }}
            - gem-cache-v1
      - run:
          name: Bundle install
          command: |
            bundle install --path vendor/bundle
      - save_cache:
          key: gem-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "Gemfile.lock" }}
          paths:
            - vendor/bundle

  test-app:
    docker:
      - image: cimg/ruby:2.7.6
    steps:
      - checkout
      - restore_cache:
          key: gem-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "Gemfile.lock" }}
      - run:
          name: Install dependencies
          command: |
            bundle install --path vendor/bundle
      - run:
          name: Run RSpec tests
          command: |
            bundle exec rspec

  scan-app:
    docker:
      - image: cimg/ruby:2.7.6
    steps:
      - checkout
      - restore_cache:
          key: gem-cache-v1-{{ arch }}-{{ .Branch }}-{{ checksum "Gemfile.lock" }}
      - run:
          name: Install dependencies
          command: |
            bundle install --path vendor/bundle
      - run:
          name: Lint with Rubocop
          command: |
            bundle exec rubocop

  upload-docker:
    docker:
      - image: cimg/ruby:2.7.6
    steps:
      - checkout
      - setup_remote_docker:
          version: 20.10.14
          docker_layer_caching: true
      - run:
          name: Build and push Docker image
          command: |
            DOCKERPATH=duongpham910/rails-capstone-project:v0.0.$CIRCLE_BUILD_NUM

            docker build --tag=rails-capstone-project .
            echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin
            docker tag rails-capstone-project $DOCKERPATH
            docker push $DOCKERPATH

  deploy-infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk add --update tar gzip curl
            pip3 install awscli
      - run:
          name: Install eksctl
          command: |
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/v0.100.0/eksctl_Linux_amd64.tar.gz" | tar xz -C /tmp
            mv /tmp/eksctl /usr/local/bin
      - run:
          name: Create cluster
          command: |
            eksctl create cluster \
              --name eksctl-${CIRCLE_WORKFLOW_ID:0:7} \
              --region=us-west-1 \
              --instance-types=t3.micro

  deploy-cluster:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk add --update tar gzip curl
            pip3 install awscli
      - run:
          name: Install kubectl
          command: |
            curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
            kubectl version --client
      - run:
          name: Update kube config
          command: |
            aws eks update-kubeconfig --region us-west-1 --name eksctl-${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Deploy rails container to eks cluster
          command: |
            kubectl apply -f eks-container-deployment.yaml
            kubectl apply -f eks-loadbalancer-service.yaml
            # See the status
            kubectl get deploy,rs,svc,pods

  # configure-infrastructure:
  #   docker:
  #     - image: python:3.7-alpine3.11
  #   steps:
  #     - checkout
  #     - add_ssh_keys:
  #         fingerprints: ["c3:1a:4a:50:3a:49:ce:83:fd:77:4c:24:52:b9:b4:c8"]
  #     - attach_workspace:
  #         at: ~/
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           apk add --update ansible tar gzip
  #           pip3 install awscli
  #     - run:
  #         name: Set ENV
  #         command: |
  #           echo ENVIROMENT=$ENVIROMENT > "backend/.env"
  #           echo TYPEORM_CONNECTION=$TYPEORM_CONNECTION >> "backend/.env"
  #           echo TYPEORM_MIGRATIONS_DIR=$TYPEORM_MIGRATIONS_DIR >> "backend/.env"
  #           echo TYPEORM_ENTITIES=$TYPEORM_ENTITIES >> "backend/.env"
  #           echo TYPEORM_MIGRATIONS=$TYPEORM_MIGRATIONS >> "backend/.env"
  #           echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
  #           echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
  #           echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
  #           echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
  #           echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"
  #     - run:
  #         name: Configure server
  #         command: |
  #           cd .circleci/ansible
  #           ansible-playbook -i inventory.txt configure-server.yml
  #     - destroy-environment:
  #         workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

  # run-migrations:
  #   docker:
  #     - image: circleci/node:13.8.0
  #   steps:
  #     - checkout
  #     - restore_cache:
  #         keys: [backend-build]
  #     - attach_workspace:
  #         at: ~/
  #     - run:
  #         name: Run migrations
  #         command: |
  #           cd backend
  #           npm install
  #           npm run migrations > migrations_dump.txt
  #     - save_cache:
  #         paths: [backend/node_modules]
  #         key: backend-build
  #     - run:
  #         name: Send migration results to kvdb
  #         command: |
  #           cat ~/project/backend/migrations_dump.txt
  #           echo "insecure" >> ~/.curlrc
  #           if grep -q "has been executed successfully." ~/project/backend/migrations_dump.txt
  #           then
  #             curl https://kvdb.io/CAaGusCeKyezrNWgEh6TWn/migration_${CIRCLE_WORKFLOW_ID:0:7}  -d '1'
  #           fi
  #     - destroy-environment:
  #         workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
  #     - revert-migrations:
  #         workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

  # deploy-backend:
  #   docker:
  #     - image: python:3.7-alpine3.11
  #   steps:
  #     - checkout
  #     - add_ssh_keys:
  #         fingerprints: ["c3:1a:4a:50:3a:49:ce:83:fd:77:4c:24:52:b9:b4:c8"]
  #     - attach_workspace:
  #         at: ~/
  #     - run:
  #         name: Set ENV
  #         command: |
  #           echo ENVIROMENT=$ENVIROMENT > "backend/.env"
  #           echo TYPEORM_CONNECTION=$TYPEORM_CONNECTION >> "backend/.env"
  #           echo TYPEORM_MIGRATIONS_DIR=$TYPEORM_MIGRATIONS_DIR >> "backend/.env"
  #           echo TYPEORM_ENTITIES=$TYPEORM_ENTITIES >> "backend/.env"
  #           echo TYPEORM_MIGRATIONS=$TYPEORM_MIGRATIONS >> "backend/.env"
  #           echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
  #           echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
  #           echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
  #           echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
  #           echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           apk add --update ansible tar gzip nodejs npm
  #           pip3 install awscli
  #     - run:
  #         name: Deploy backend
  #         command: |
  #           cd backend
  #           npm i
  #           npm run build
  #           cd ..
  #           # Zip the directory
  #           tar -C backend -czvf artifact.tar.gz .
  #           cd .circleci/ansible
  #           echo "Contents  of the inventory.txt file is -------"
  #           cat inventory.txt
  #           ansible-playbook -i inventory.txt deploy-backend.yml
  #     - destroy-environment:
  #         workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
  #     - revert-migrations:
  #         workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

  # smoke-test:
  #   docker:
  #     - image: python:3.7-alpine3.11
  #   steps:
  #     - checkout
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           apk add --update curl nodejs npm
  #           pip3 install awscli
  #     - run:
  #         name: Backend smoke test.
  #         command: |
  #           export BACKEND_IP=$(aws ec2 describe-instances \
  #             --query 'Reservations[*].Instances[*].PublicIpAddress' \
  #             --filters Name=tag:Name,Values="backend-${CIRCLE_WORKFLOW_ID:0:7}" \
  #             --output text)
  #           export API_URL="http://${BACKEND_IP}:3030"
  #           echo "${API_URL}"
  #           if curl "${API_URL}/api/status" | grep "ok"
  #           then
  #               return 0
  #           else
  #               return 1
  #           fi
  #     - run:
  #         name: Frontend smoke test.
  #         command: |
  #           URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-us-west-1.amazonaws.com/#/employees"
  #           echo ${URL}
  #           if curl -s ${URL} | grep "Welcome"
  #           then
  #             return 0
  #           else
  #             return 1
  #           fi
  #     - destroy-environment:
  #         workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
  #     - revert-migrations:
  #         workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

  # cleanup:
  #   docker:
  #     - image: amazon/aws-cli
  #   steps:
  #     - checkout
  #     - run: yum install -y tar gzip
  #     - attach_workspace:
  #         at: ~/
  #     - run:
  #         name: Remove old stacks and files
  #         command: |
  #           cat ~/OldWorkflowID.txt
  #           OldWorkflowID=$(cat ~/OldWorkflowID.txt)
  #           echo OldWorkflowID: "${OldWorkflowID}"

  #           if [[ "${CIRCLE_WORKFLOW_ID:0:7}" != "${OldWorkflowID}" ]]
  #           then
  #             aws s3 rm "s3://udapeople-${OldWorkflowID}" --recursive
  #             aws cloudformation delete-stack --stack-name "udapeople-backend-${OldWorkflowID}"
  #             aws cloudformation delete-stack --stack-name "udapeople-frontend-${OldWorkflowID}"
  #           else
  #             echo "Cannot cleanup"
  #           fi

workflows:
  default:
    jobs:
      - build-app
      - test-app:
          requires: [build-app]
      - scan-app:
          requires: [build-app]
      - upload-docker:
          requires: [test-app, scan-app]
      - deploy-infrastructure:
          requires: [test-app, scan-app]
      - deploy-cluster:
          requires: [upload-docker, deploy-infrastructure]
      # - run-migrations:
      #     requires: [configure-infrastructure]
      # - deploy-backend:
      #     requires: [run-migrations]
      # - smoke-test:
      #     requires: [deploy-backend]
      # - cleanup:
      #     requires: [smoke-test]
